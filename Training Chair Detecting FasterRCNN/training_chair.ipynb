{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.18.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting cython\n",
      "  Downloading Cython-3.0.10-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Downloading Cython-3.0.10-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.8 MB 6.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.6/2.8 MB 7.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.8 MB 7.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.5/2.8 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.2/2.8 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.8/2.8 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: cython\n",
      "Successfully installed cython-3.0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/fvcore'\": Expected package name at the start of dependency specifier\n",
      "    'git+https://github.com/facebookresearch/fvcore'\n",
      "    ^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement detectron2 (from versions: none)\n",
      "ERROR: No matching distribution found for detectron2\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install cython\n",
    "!pip install 'git+https://github.com/facebookresearch/fvcore'\n",
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu113/torch1.10/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
      "  Cloning https://github.com/facebookresearch/fvcore.git to c:\\users\\dawoo\\appdata\\local\\temp\\pip-req-build-h5ycrw22\n",
      "  Resolved https://github.com/facebookresearch/fvcore.git to commit 1d61132af7413155fedc197f72903d01c624bd01\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore==0.1.6) (1.26.4)\n",
      "Collecting yacs>=0.1.6 (from fvcore==0.1.6)\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore==0.1.6) (6.0.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore==0.1.6) (4.66.4)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore==0.1.6) (2.4.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore==0.1.6) (10.2.0)\n",
      "Collecting tabulate (from fvcore==0.1.6)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting iopath>=0.1.7 (from fvcore==0.1.6)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "     ---------------------------------------- 0.0/42.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.2/42.2 kB ? eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from iopath>=0.1.7->fvcore==0.1.6) (4.11.0)\n",
      "Collecting portalocker (from iopath>=0.1.7->fvcore==0.1.6)\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->fvcore==0.1.6) (0.4.6)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from portalocker->iopath>=0.1.7->fvcore==0.1.6) (306)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: fvcore, iopath\n",
      "  Building wheel for fvcore (setup.py): started\n",
      "  Building wheel for fvcore (setup.py): finished with status 'done'\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.6-py3-none-any.whl size=66103 sha256=962d49aa31b09c0a529e3758f7de3a1bced61d16e22b26beb850863d8c56845f\n",
      "  Stored in directory: C:\\Users\\dawoo\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-kdcp3sqe\\wheels\\f0\\0c\\4f\\d358b3fbbc075812561fc600352afc7c17c6fb223304e39d97\n",
      "  Building wheel for iopath (setup.py): started\n",
      "  Building wheel for iopath (setup.py): finished with status 'done'\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31543 sha256=2e6f675a03d286b191189093c5c80c85cac394fad9ca7895ae60d74d6cb42f81\n",
      "  Stored in directory: c:\\users\\dawoo\\appdata\\local\\pip\\cache\\wheels\\7c\\96\\04\\4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
      "Successfully built fvcore iopath\n",
      "Installing collected packages: yacs, tabulate, portalocker, iopath, fvcore\n",
      "Successfully installed fvcore-0.1.6 iopath-0.1.10 portalocker-2.10.0 tabulate-0.9.0 yacs-0.1.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/fvcore.git 'C:\\Users\\dawoo\\AppData\\Local\\Temp\\pip-req-build-h5ycrw22'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/facebookresearch/fvcore.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu125/torch2.0/index.html\n",
      "Requirement already satisfied: detectron2 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: Pillow>=7.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (10.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (3.9.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (2.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (2.4.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (0.1.8)\n",
      "Requirement already satisfied: tabulate in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (3.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (4.66.4)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (2.16.2)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (1.3.2)\n",
      "Requirement already satisfied: black in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from detectron2) (24.4.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from detectron2) (24.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (6.0.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from hydra-core>=1.1->detectron2) (4.9.3)\n",
      "Requirement already satisfied: portalocker in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->detectron2) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->detectron2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->detectron2) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->detectron2) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->detectron2) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->detectron2) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4.29.0->detectron2) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black->detectron2) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black->detectron2) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from black->detectron2) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from black->detectron2) (4.2.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (4.25.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (69.5.1)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard->detectron2) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard->detectron2) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dawoo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->detectron2) (2.1.5)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\dawoo\\appdata\\roaming\\python\\python312\\site-packages (from portalocker->iopath<0.1.10,>=0.1.7->detectron2) (306)\n"
     ]
    }
   ],
   "source": [
    "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu125/torch2.0/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 17:53:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 17:53:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 17:53:09 d2.data.datasets.coco]: \u001b[0mLoaded 12774 images in COCO format from D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection_FasterRCNN/dataset/annotations/instances_train2017.json\n",
      "\u001b[32m[07/02 17:53:09 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 12774 images left.\n",
      "\u001b[32m[07/02 17:53:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[07/02 17:53:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[07/02 17:53:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 17:53:09 d2.data.common]: \u001b[0mSerializing 12774 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 17:53:09 d2.data.common]: \u001b[0mSerialized dataset takes 20.21 MiB\n",
      "\u001b[32m[07/02 17:53:09 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 17:53:09 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[07/02 17:53:09 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 17:53:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[07/02 17:53:23 d2.utils.events]: \u001b[0m eta: 1:23:06  iter: 19  total_loss: 1.358  loss_cls: 0.6555  loss_box_reg: 0.6172  loss_rpn_cls: 0.05052  loss_rpn_loc: 0.01919    time: 0.4879  last_time: 0.4409  data_time: 0.1774  last_data_time: 0.0012   lr: 4.9953e-06  max_mem: 4296M\n",
      "\u001b[32m[07/02 17:53:33 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 39  total_loss: 1.362  loss_cls: 0.6377  loss_box_reg: 0.6531  loss_rpn_cls: 0.0401  loss_rpn_loc: 0.01268    time: 0.4864  last_time: 0.4647  data_time: 0.0014  last_data_time: 0.0007   lr: 9.9902e-06  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:53:42 d2.utils.events]: \u001b[0m eta: 1:18:55  iter: 59  total_loss: 1.321  loss_cls: 0.6118  loss_box_reg: 0.6111  loss_rpn_cls: 0.04785  loss_rpn_loc: 0.02175    time: 0.4807  last_time: 0.4847  data_time: 0.0013  last_data_time: 0.0009   lr: 1.4985e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:53:52 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 79  total_loss: 1.22  loss_cls: 0.5487  loss_box_reg: 0.6041  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.01244    time: 0.4761  last_time: 0.4651  data_time: 0.0013  last_data_time: 0.0016   lr: 1.998e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:01 d2.utils.events]: \u001b[0m eta: 1:17:50  iter: 99  total_loss: 1.15  loss_cls: 0.4856  loss_box_reg: 0.5898  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.01655    time: 0.4746  last_time: 0.4401  data_time: 0.0013  last_data_time: 0.0015   lr: 2.4975e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:11 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 119  total_loss: 1.128  loss_cls: 0.4482  loss_box_reg: 0.6491  loss_rpn_cls: 0.03855  loss_rpn_loc: 0.0126    time: 0.4783  last_time: 0.4399  data_time: 0.0014  last_data_time: 0.0014   lr: 2.997e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:20 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 139  total_loss: 1.095  loss_cls: 0.4189  loss_box_reg: 0.6028  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.01025    time: 0.4778  last_time: 0.4263  data_time: 0.0013  last_data_time: 0.0008   lr: 3.4965e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:30 d2.utils.events]: \u001b[0m eta: 1:18:16  iter: 159  total_loss: 1.144  loss_cls: 0.3893  loss_box_reg: 0.618  loss_rpn_cls: 0.04264  loss_rpn_loc: 0.0112    time: 0.4812  last_time: 0.5678  data_time: 0.0013  last_data_time: 0.0012   lr: 3.996e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:40 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 179  total_loss: 1.084  loss_cls: 0.4015  loss_box_reg: 0.607  loss_rpn_cls: 0.06512  loss_rpn_loc: 0.01978    time: 0.4821  last_time: 0.5235  data_time: 0.0013  last_data_time: 0.0011   lr: 4.4955e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:54:51 d2.utils.events]: \u001b[0m eta: 1:19:21  iter: 199  total_loss: 0.9596  loss_cls: 0.3403  loss_box_reg: 0.5876  loss_rpn_cls: 0.04458  loss_rpn_loc: 0.01219    time: 0.4861  last_time: 0.5242  data_time: 0.0013  last_data_time: 0.0016   lr: 4.995e-05  max_mem: 4297M\n",
      "\u001b[32m[07/02 17:55:01 d2.utils.events]: \u001b[0m eta: 1:19:11  iter: 219  total_loss: 1.181  loss_cls: 0.3835  loss_box_reg: 0.7233  loss_rpn_cls: 0.05102  loss_rpn_loc: 0.01507    time: 0.4872  last_time: 0.4644  data_time: 0.0014  last_data_time: 0.0021   lr: 5.4945e-05  max_mem: 4298M\n",
      "\u001b[32m[07/02 17:55:11 d2.utils.events]: \u001b[0m eta: 1:19:12  iter: 239  total_loss: 0.9942  loss_cls: 0.33  loss_box_reg: 0.5843  loss_rpn_cls: 0.04361  loss_rpn_loc: 0.01314    time: 0.4879  last_time: 0.5251  data_time: 0.0015  last_data_time: 0.0015   lr: 5.994e-05  max_mem: 4298M\n",
      "\u001b[32m[07/02 17:55:21 d2.utils.events]: \u001b[0m eta: 1:19:11  iter: 259  total_loss: 1.067  loss_cls: 0.3232  loss_box_reg: 0.6813  loss_rpn_cls: 0.03062  loss_rpn_loc: 0.01088    time: 0.4898  last_time: 0.5504  data_time: 0.0015  last_data_time: 0.0019   lr: 6.4935e-05  max_mem: 4386M\n",
      "\u001b[32m[07/02 17:55:31 d2.utils.events]: \u001b[0m eta: 1:19:09  iter: 279  total_loss: 0.9337  loss_cls: 0.298  loss_box_reg: 0.5733  loss_rpn_cls: 0.02879  loss_rpn_loc: 0.007291    time: 0.4905  last_time: 0.5048  data_time: 0.0013  last_data_time: 0.0012   lr: 6.993e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:55:41 d2.utils.events]: \u001b[0m eta: 1:19:46  iter: 299  total_loss: 0.8595  loss_cls: 0.273  loss_box_reg: 0.5415  loss_rpn_cls: 0.0324  loss_rpn_loc: 0.0094    time: 0.4926  last_time: 0.4634  data_time: 0.0015  last_data_time: 0.0023   lr: 7.4925e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:55:51 d2.utils.events]: \u001b[0m eta: 1:19:41  iter: 319  total_loss: 0.9296  loss_cls: 0.2682  loss_box_reg: 0.6054  loss_rpn_cls: 0.03413  loss_rpn_loc: 0.007893    time: 0.4926  last_time: 0.4565  data_time: 0.0012  last_data_time: 0.0016   lr: 7.992e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:01 d2.utils.events]: \u001b[0m eta: 1:20:01  iter: 339  total_loss: 0.868  loss_cls: 0.2584  loss_box_reg: 0.5433  loss_rpn_cls: 0.03081  loss_rpn_loc: 0.01358    time: 0.4931  last_time: 0.6463  data_time: 0.0014  last_data_time: 0.0018   lr: 8.4915e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:12 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 359  total_loss: 0.8586  loss_cls: 0.231  loss_box_reg: 0.5341  loss_rpn_cls: 0.04019  loss_rpn_loc: 0.01206    time: 0.4955  last_time: 0.5384  data_time: 0.0015  last_data_time: 0.0021   lr: 8.991e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:22 d2.utils.events]: \u001b[0m eta: 1:19:41  iter: 379  total_loss: 0.7579  loss_cls: 0.2135  loss_box_reg: 0.4709  loss_rpn_cls: 0.03353  loss_rpn_loc: 0.01029    time: 0.4951  last_time: 0.4653  data_time: 0.0015  last_data_time: 0.0009   lr: 9.4905e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:32 d2.utils.events]: \u001b[0m eta: 1:19:36  iter: 399  total_loss: 0.8113  loss_cls: 0.2098  loss_box_reg: 0.5239  loss_rpn_cls: 0.04506  loss_rpn_loc: 0.01512    time: 0.4961  last_time: 0.5435  data_time: 0.0016  last_data_time: 0.0011   lr: 9.99e-05  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:43 d2.utils.events]: \u001b[0m eta: 1:19:41  iter: 419  total_loss: 0.7506  loss_cls: 0.2072  loss_box_reg: 0.4545  loss_rpn_cls: 0.03348  loss_rpn_loc: 0.01426    time: 0.4980  last_time: 0.5133  data_time: 0.0014  last_data_time: 0.0012   lr: 0.0001049  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:56:53 d2.utils.events]: \u001b[0m eta: 1:19:44  iter: 439  total_loss: 0.7816  loss_cls: 0.223  loss_box_reg: 0.4959  loss_rpn_cls: 0.04077  loss_rpn_loc: 0.01671    time: 0.4981  last_time: 0.5413  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00010989  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:03 d2.utils.events]: \u001b[0m eta: 1:19:36  iter: 459  total_loss: 0.7568  loss_cls: 0.2153  loss_box_reg: 0.5249  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01461    time: 0.4985  last_time: 0.5034  data_time: 0.0014  last_data_time: 0.0004   lr: 0.00011489  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:13 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 479  total_loss: 0.7714  loss_cls: 0.2207  loss_box_reg: 0.5022  loss_rpn_cls: 0.0269  loss_rpn_loc: 0.01209    time: 0.4993  last_time: 0.4890  data_time: 0.0016  last_data_time: 0.0029   lr: 0.00011988  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:23 d2.utils.events]: \u001b[0m eta: 1:19:20  iter: 499  total_loss: 0.6263  loss_cls: 0.2096  loss_box_reg: 0.3852  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.01178    time: 0.5000  last_time: 0.4312  data_time: 0.0013  last_data_time: 0.0008   lr: 0.00012488  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:34 d2.utils.events]: \u001b[0m eta: 1:19:34  iter: 519  total_loss: 0.659  loss_cls: 0.1873  loss_box_reg: 0.3675  loss_rpn_cls: 0.02128  loss_rpn_loc: 0.01467    time: 0.5007  last_time: 0.5549  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00012987  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:44 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 539  total_loss: 0.5966  loss_cls: 0.1662  loss_box_reg: 0.3488  loss_rpn_cls: 0.03676  loss_rpn_loc: 0.01939    time: 0.5001  last_time: 0.4602  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00013487  max_mem: 4387M\n",
      "\u001b[32m[07/02 17:57:54 d2.utils.events]: \u001b[0m eta: 1:19:04  iter: 559  total_loss: 0.6435  loss_cls: 0.2056  loss_box_reg: 0.3965  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.01441    time: 0.5003  last_time: 0.4869  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00013986  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:04 d2.utils.events]: \u001b[0m eta: 1:19:03  iter: 579  total_loss: 0.6576  loss_cls: 0.2117  loss_box_reg: 0.4177  loss_rpn_cls: 0.03168  loss_rpn_loc: 0.01451    time: 0.5011  last_time: 0.5173  data_time: 0.0014  last_data_time: 0.0017   lr: 0.00014486  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:14 d2.utils.events]: \u001b[0m eta: 1:18:57  iter: 599  total_loss: 0.6507  loss_cls: 0.2053  loss_box_reg: 0.3863  loss_rpn_cls: 0.02883  loss_rpn_loc: 0.01439    time: 0.5013  last_time: 0.5901  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00014985  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:25 d2.utils.events]: \u001b[0m eta: 1:18:58  iter: 619  total_loss: 0.6622  loss_cls: 0.1975  loss_box_reg: 0.3519  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.01142    time: 0.5020  last_time: 0.5025  data_time: 0.0014  last_data_time: 0.0020   lr: 0.00015485  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:35 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 639  total_loss: 0.5642  loss_cls: 0.1903  loss_box_reg: 0.3438  loss_rpn_cls: 0.02414  loss_rpn_loc: 0.01012    time: 0.5019  last_time: 0.4957  data_time: 0.0015  last_data_time: 0.0023   lr: 0.00015984  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:45 d2.utils.events]: \u001b[0m eta: 1:18:37  iter: 659  total_loss: 0.5357  loss_cls: 0.1646  loss_box_reg: 0.3181  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.009004    time: 0.5025  last_time: 0.5456  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00016484  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:58:56 d2.utils.events]: \u001b[0m eta: 1:18:23  iter: 679  total_loss: 0.5406  loss_cls: 0.1882  loss_box_reg: 0.3059  loss_rpn_cls: 0.03095  loss_rpn_loc: 0.0135    time: 0.5029  last_time: 0.5426  data_time: 0.0013  last_data_time: 0.0008   lr: 0.00016983  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:06 d2.utils.events]: \u001b[0m eta: 1:18:14  iter: 699  total_loss: 0.561  loss_cls: 0.1751  loss_box_reg: 0.3538  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.01383    time: 0.5030  last_time: 0.3675  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00017483  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:16 d2.utils.events]: \u001b[0m eta: 1:18:15  iter: 719  total_loss: 0.636  loss_cls: 0.1998  loss_box_reg: 0.3932  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.01651    time: 0.5039  last_time: 0.5958  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00017982  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:27 d2.utils.events]: \u001b[0m eta: 1:18:28  iter: 739  total_loss: 0.5402  loss_cls: 0.1241  loss_box_reg: 0.357  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.01644    time: 0.5051  last_time: 0.4996  data_time: 0.0014  last_data_time: 0.0024   lr: 0.00018482  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:38 d2.utils.events]: \u001b[0m eta: 1:18:19  iter: 759  total_loss: 0.5171  loss_cls: 0.1656  loss_box_reg: 0.3158  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.01148    time: 0.5055  last_time: 0.5935  data_time: 0.0015  last_data_time: 0.0009   lr: 0.00018981  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:48 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 779  total_loss: 0.7493  loss_cls: 0.2208  loss_box_reg: 0.4146  loss_rpn_cls: 0.04243  loss_rpn_loc: 0.02385    time: 0.5060  last_time: 0.5823  data_time: 0.0017  last_data_time: 0.0011   lr: 0.00019481  max_mem: 4388M\n",
      "\u001b[32m[07/02 17:59:59 d2.utils.events]: \u001b[0m eta: 1:18:17  iter: 799  total_loss: 0.5378  loss_cls: 0.1693  loss_box_reg: 0.3433  loss_rpn_cls: 0.02357  loss_rpn_loc: 0.01063    time: 0.5071  last_time: 0.5794  data_time: 0.0016  last_data_time: 0.0014   lr: 0.0001998  max_mem: 4388M\n",
      "\u001b[32m[07/02 18:00:10 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 819  total_loss: 0.711  loss_cls: 0.2195  loss_box_reg: 0.3764  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.01741    time: 0.5073  last_time: 0.5435  data_time: 0.0014  last_data_time: 0.0018   lr: 0.0002048  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:00:20 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 839  total_loss: 0.6479  loss_cls: 0.2017  loss_box_reg: 0.3682  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.01331    time: 0.5071  last_time: 0.6001  data_time: 0.0016  last_data_time: 0.0011   lr: 0.00020979  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:00:30 d2.utils.events]: \u001b[0m eta: 1:17:50  iter: 859  total_loss: 0.6611  loss_cls: 0.1992  loss_box_reg: 0.373  loss_rpn_cls: 0.0336  loss_rpn_loc: 0.01564    time: 0.5072  last_time: 0.4700  data_time: 0.0015  last_data_time: 0.0016   lr: 0.00021479  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:00:40 d2.utils.events]: \u001b[0m eta: 1:17:41  iter: 879  total_loss: 0.5942  loss_cls: 0.1784  loss_box_reg: 0.3466  loss_rpn_cls: 0.03437  loss_rpn_loc: 0.01383    time: 0.5077  last_time: 0.4986  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00021978  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:00:51 d2.utils.events]: \u001b[0m eta: 1:17:31  iter: 899  total_loss: 0.6635  loss_cls: 0.2048  loss_box_reg: 0.4003  loss_rpn_cls: 0.04313  loss_rpn_loc: 0.01374    time: 0.5082  last_time: 0.4757  data_time: 0.0015  last_data_time: 0.0024   lr: 0.00022478  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:01 d2.utils.events]: \u001b[0m eta: 1:17:16  iter: 919  total_loss: 0.5629  loss_cls: 0.1908  loss_box_reg: 0.3312  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.009502    time: 0.5081  last_time: 0.4393  data_time: 0.0014  last_data_time: 0.0024   lr: 0.00022977  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:12 d2.utils.events]: \u001b[0m eta: 1:17:10  iter: 939  total_loss: 0.4824  loss_cls: 0.153  loss_box_reg: 0.3342  loss_rpn_cls: 0.015  loss_rpn_loc: 0.009624    time: 0.5085  last_time: 0.4473  data_time: 0.0015  last_data_time: 0.0018   lr: 0.00023477  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:21 d2.utils.events]: \u001b[0m eta: 1:16:45  iter: 959  total_loss: 0.5354  loss_cls: 0.1787  loss_box_reg: 0.3012  loss_rpn_cls: 0.0213  loss_rpn_loc: 0.01312    time: 0.5081  last_time: 0.4400  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00023976  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:32 d2.utils.events]: \u001b[0m eta: 1:16:43  iter: 979  total_loss: 0.6578  loss_cls: 0.1989  loss_box_reg: 0.3631  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.01388    time: 0.5084  last_time: 0.5424  data_time: 0.0014  last_data_time: 0.0017   lr: 0.00024476  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:42 d2.utils.events]: \u001b[0m eta: 1:16:36  iter: 999  total_loss: 0.6116  loss_cls: 0.206  loss_box_reg: 0.383  loss_rpn_cls: 0.0281  loss_rpn_loc: 0.01191    time: 0.5088  last_time: 0.5663  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00024975  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:01:54 d2.utils.events]: \u001b[0m eta: 1:16:39  iter: 1019  total_loss: 0.4663  loss_cls: 0.1498  loss_box_reg: 0.289  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.007251    time: 0.5097  last_time: 0.5279  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:04 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 1039  total_loss: 0.4803  loss_cls: 0.1455  loss_box_reg: 0.3131  loss_rpn_cls: 0.015  loss_rpn_loc: 0.007967    time: 0.5100  last_time: 0.4876  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:14 d2.utils.events]: \u001b[0m eta: 1:16:50  iter: 1059  total_loss: 0.6347  loss_cls: 0.2298  loss_box_reg: 0.387  loss_rpn_cls: 0.02245  loss_rpn_loc: 0.007961    time: 0.5101  last_time: 0.5631  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:25 d2.utils.events]: \u001b[0m eta: 1:16:54  iter: 1079  total_loss: 0.6173  loss_cls: 0.1755  loss_box_reg: 0.3608  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.009298    time: 0.5102  last_time: 0.6616  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:35 d2.utils.events]: \u001b[0m eta: 1:16:55  iter: 1099  total_loss: 0.643  loss_cls: 0.1892  loss_box_reg: 0.3614  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.01303    time: 0.5107  last_time: 0.4678  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:46 d2.utils.events]: \u001b[0m eta: 1:16:53  iter: 1119  total_loss: 0.3923  loss_cls: 0.1469  loss_box_reg: 0.2594  loss_rpn_cls: 0.018  loss_rpn_loc: 0.008671    time: 0.5110  last_time: 0.5497  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:02:57 d2.utils.events]: \u001b[0m eta: 1:16:54  iter: 1139  total_loss: 0.6896  loss_cls: 0.2117  loss_box_reg: 0.405  loss_rpn_cls: 0.03501  loss_rpn_loc: 0.0187    time: 0.5115  last_time: 0.5094  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:07 d2.utils.events]: \u001b[0m eta: 1:16:46  iter: 1159  total_loss: 0.6208  loss_cls: 0.1859  loss_box_reg: 0.3637  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.01422    time: 0.5117  last_time: 0.4512  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:17 d2.utils.events]: \u001b[0m eta: 1:16:38  iter: 1179  total_loss: 0.6887  loss_cls: 0.2311  loss_box_reg: 0.4012  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.01894    time: 0.5117  last_time: 0.5945  data_time: 0.0014  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:28 d2.utils.events]: \u001b[0m eta: 1:16:21  iter: 1199  total_loss: 0.614  loss_cls: 0.1664  loss_box_reg: 0.3881  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.01037    time: 0.5116  last_time: 0.3920  data_time: 0.0017  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:38 d2.utils.events]: \u001b[0m eta: 1:16:17  iter: 1219  total_loss: 0.5387  loss_cls: 0.1723  loss_box_reg: 0.3115  loss_rpn_cls: 0.01953  loss_rpn_loc: 0.01534    time: 0.5117  last_time: 0.5847  data_time: 0.0016  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:48 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 1239  total_loss: 0.6401  loss_cls: 0.2265  loss_box_reg: 0.3836  loss_rpn_cls: 0.01819  loss_rpn_loc: 0.01325    time: 0.5118  last_time: 0.5662  data_time: 0.0014  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:03:59 d2.utils.events]: \u001b[0m eta: 1:16:04  iter: 1259  total_loss: 0.5469  loss_cls: 0.1783  loss_box_reg: 0.3204  loss_rpn_cls: 0.01538  loss_rpn_loc: 0.012    time: 0.5119  last_time: 0.4747  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:04:09 d2.utils.events]: \u001b[0m eta: 1:16:03  iter: 1279  total_loss: 0.6297  loss_cls: 0.2039  loss_box_reg: 0.3804  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.01728    time: 0.5123  last_time: 0.4951  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:04:20 d2.utils.events]: \u001b[0m eta: 1:15:55  iter: 1299  total_loss: 0.5489  loss_cls: 0.1706  loss_box_reg: 0.351  loss_rpn_cls: 0.01227  loss_rpn_loc: 0.007364    time: 0.5126  last_time: 0.4441  data_time: 0.0015  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:04:31 d2.utils.events]: \u001b[0m eta: 1:15:49  iter: 1319  total_loss: 0.5603  loss_cls: 0.1591  loss_box_reg: 0.333  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.01498    time: 0.5128  last_time: 0.5014  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:04:41 d2.utils.events]: \u001b[0m eta: 1:15:34  iter: 1339  total_loss: 0.4845  loss_cls: 0.1529  loss_box_reg: 0.3082  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01206    time: 0.5129  last_time: 0.4092  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:04:51 d2.utils.events]: \u001b[0m eta: 1:15:22  iter: 1359  total_loss: 0.4967  loss_cls: 0.1498  loss_box_reg: 0.3007  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.01085    time: 0.5130  last_time: 0.6035  data_time: 0.0015  last_data_time: 0.0027   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:02 d2.utils.events]: \u001b[0m eta: 1:15:16  iter: 1379  total_loss: 0.4791  loss_cls: 0.1618  loss_box_reg: 0.3181  loss_rpn_cls: 0.02279  loss_rpn_loc: 0.01269    time: 0.5133  last_time: 0.4373  data_time: 0.0016  last_data_time: 0.0030   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:13 d2.utils.events]: \u001b[0m eta: 1:15:07  iter: 1399  total_loss: 0.5918  loss_cls: 0.1697  loss_box_reg: 0.3861  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.01453    time: 0.5135  last_time: 0.4605  data_time: 0.0014  last_data_time: 0.0026   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:23 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 1419  total_loss: 0.6375  loss_cls: 0.2099  loss_box_reg: 0.3777  loss_rpn_cls: 0.02494  loss_rpn_loc: 0.01565    time: 0.5134  last_time: 0.6149  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:33 d2.utils.events]: \u001b[0m eta: 1:14:40  iter: 1439  total_loss: 0.596  loss_cls: 0.1804  loss_box_reg: 0.354  loss_rpn_cls: 0.0284  loss_rpn_loc: 0.01049    time: 0.5135  last_time: 0.4216  data_time: 0.0015  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:44 d2.utils.events]: \u001b[0m eta: 1:14:36  iter: 1459  total_loss: 0.5257  loss_cls: 0.1875  loss_box_reg: 0.3132  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.00719    time: 0.5136  last_time: 0.5293  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:05:54 d2.utils.events]: \u001b[0m eta: 1:14:25  iter: 1479  total_loss: 0.659  loss_cls: 0.2079  loss_box_reg: 0.3705  loss_rpn_cls: 0.02662  loss_rpn_loc: 0.01657    time: 0.5138  last_time: 0.5749  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:05 d2.utils.events]: \u001b[0m eta: 1:14:16  iter: 1499  total_loss: 0.6332  loss_cls: 0.1905  loss_box_reg: 0.4009  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.01337    time: 0.5139  last_time: 0.4242  data_time: 0.0016  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:15 d2.utils.events]: \u001b[0m eta: 1:14:04  iter: 1519  total_loss: 0.5471  loss_cls: 0.1916  loss_box_reg: 0.33  loss_rpn_cls: 0.01663  loss_rpn_loc: 0.008544    time: 0.5141  last_time: 0.5505  data_time: 0.0015  last_data_time: 0.0024   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:26 d2.utils.events]: \u001b[0m eta: 1:14:06  iter: 1539  total_loss: 0.5259  loss_cls: 0.1657  loss_box_reg: 0.3366  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.0112    time: 0.5146  last_time: 0.5655  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:37 d2.utils.events]: \u001b[0m eta: 1:13:55  iter: 1559  total_loss: 0.6846  loss_cls: 0.186  loss_box_reg: 0.378  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.01263    time: 0.5146  last_time: 0.5608  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:47 d2.utils.events]: \u001b[0m eta: 1:13:41  iter: 1579  total_loss: 0.621  loss_cls: 0.1903  loss_box_reg: 0.3799  loss_rpn_cls: 0.02329  loss_rpn_loc: 0.01328    time: 0.5148  last_time: 0.5485  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:06:58 d2.utils.events]: \u001b[0m eta: 1:13:34  iter: 1599  total_loss: 0.5247  loss_cls: 0.1552  loss_box_reg: 0.3197  loss_rpn_cls: 0.01321  loss_rpn_loc: 0.007909    time: 0.5152  last_time: 0.5060  data_time: 0.0015  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:07:08 d2.utils.events]: \u001b[0m eta: 1:13:20  iter: 1619  total_loss: 0.4342  loss_cls: 0.1413  loss_box_reg: 0.2831  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.0077    time: 0.5152  last_time: 0.5199  data_time: 0.0015  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:07:19 d2.utils.events]: \u001b[0m eta: 1:13:18  iter: 1639  total_loss: 0.5745  loss_cls: 0.1789  loss_box_reg: 0.3781  loss_rpn_cls: 0.009742  loss_rpn_loc: 0.01065    time: 0.5153  last_time: 0.4850  data_time: 0.0015  last_data_time: 0.0006   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:07:29 d2.utils.events]: \u001b[0m eta: 1:13:08  iter: 1659  total_loss: 0.5224  loss_cls: 0.1636  loss_box_reg: 0.3203  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.01272    time: 0.5154  last_time: 0.5042  data_time: 0.0015  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:07:40 d2.utils.events]: \u001b[0m eta: 1:13:00  iter: 1679  total_loss: 0.6394  loss_cls: 0.1904  loss_box_reg: 0.397  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.01699    time: 0.5156  last_time: 0.4854  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:07:51 d2.utils.events]: \u001b[0m eta: 1:12:48  iter: 1699  total_loss: 0.3733  loss_cls: 0.1462  loss_box_reg: 0.2013  loss_rpn_cls: 0.008692  loss_rpn_loc: 0.006187    time: 0.5157  last_time: 0.5034  data_time: 0.0014  last_data_time: 0.0027   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:01 d2.utils.events]: \u001b[0m eta: 1:12:31  iter: 1719  total_loss: 0.6796  loss_cls: 0.2317  loss_box_reg: 0.3752  loss_rpn_cls: 0.0207  loss_rpn_loc: 0.01647    time: 0.5155  last_time: 0.5524  data_time: 0.0014  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:11 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 1739  total_loss: 0.6067  loss_cls: 0.1989  loss_box_reg: 0.3688  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.009454    time: 0.5154  last_time: 0.4223  data_time: 0.0015  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:21 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 1759  total_loss: 0.5665  loss_cls: 0.1761  loss_box_reg: 0.3265  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.02338    time: 0.5153  last_time: 0.5476  data_time: 0.0013  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:31 d2.utils.events]: \u001b[0m eta: 1:11:55  iter: 1779  total_loss: 0.5255  loss_cls: 0.1583  loss_box_reg: 0.3308  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.01146    time: 0.5155  last_time: 0.5292  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:42 d2.utils.events]: \u001b[0m eta: 1:11:41  iter: 1799  total_loss: 0.4529  loss_cls: 0.1592  loss_box_reg: 0.3411  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.01048    time: 0.5157  last_time: 0.4096  data_time: 0.0015  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:08:53 d2.utils.events]: \u001b[0m eta: 1:11:32  iter: 1819  total_loss: 0.7975  loss_cls: 0.2151  loss_box_reg: 0.4837  loss_rpn_cls: 0.03071  loss_rpn_loc: 0.02563    time: 0.5160  last_time: 0.5239  data_time: 0.0016  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:03 d2.utils.events]: \u001b[0m eta: 1:11:25  iter: 1839  total_loss: 0.5206  loss_cls: 0.1841  loss_box_reg: 0.2965  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01338    time: 0.5160  last_time: 0.5620  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:14 d2.utils.events]: \u001b[0m eta: 1:11:18  iter: 1859  total_loss: 0.5704  loss_cls: 0.1809  loss_box_reg: 0.3569  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.009038    time: 0.5161  last_time: 0.5393  data_time: 0.0015  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:24 d2.utils.events]: \u001b[0m eta: 1:11:08  iter: 1879  total_loss: 0.543  loss_cls: 0.21  loss_box_reg: 0.3045  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.01272    time: 0.5161  last_time: 0.4274  data_time: 0.0015  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:35 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 1899  total_loss: 0.5896  loss_cls: 0.1941  loss_box_reg: 0.307  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.01895    time: 0.5162  last_time: 0.5700  data_time: 0.0015  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:45 d2.utils.events]: \u001b[0m eta: 1:10:54  iter: 1919  total_loss: 0.5534  loss_cls: 0.1886  loss_box_reg: 0.2909  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.01147    time: 0.5163  last_time: 0.4414  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:09:56 d2.utils.events]: \u001b[0m eta: 1:10:48  iter: 1939  total_loss: 0.6197  loss_cls: 0.1961  loss_box_reg: 0.3827  loss_rpn_cls: 0.01868  loss_rpn_loc: 0.0131    time: 0.5167  last_time: 0.5618  data_time: 0.0015  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:10:07 d2.utils.events]: \u001b[0m eta: 1:10:41  iter: 1959  total_loss: 0.6252  loss_cls: 0.1821  loss_box_reg: 0.3406  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.01121    time: 0.5168  last_time: 0.5605  data_time: 0.0015  last_data_time: 0.0029   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:10:18 d2.utils.events]: \u001b[0m eta: 1:10:30  iter: 1979  total_loss: 0.576  loss_cls: 0.1766  loss_box_reg: 0.3507  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.01013    time: 0.5170  last_time: 0.4862  data_time: 0.0021  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:10:28 d2.utils.events]: \u001b[0m eta: 1:10:19  iter: 1999  total_loss: 0.5632  loss_cls: 0.1636  loss_box_reg: 0.301  loss_rpn_cls: 0.02574  loss_rpn_loc: 0.01048    time: 0.5173  last_time: 0.5209  data_time: 0.0019  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:10:40 d2.utils.events]: \u001b[0m eta: 1:10:07  iter: 2019  total_loss: 0.5862  loss_cls: 0.1745  loss_box_reg: 0.303  loss_rpn_cls: 0.01769  loss_rpn_loc: 0.01269    time: 0.5176  last_time: 0.5721  data_time: 0.0020  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:10:50 d2.utils.events]: \u001b[0m eta: 1:09:58  iter: 2039  total_loss: 0.5221  loss_cls: 0.1774  loss_box_reg: 0.3164  loss_rpn_cls: 0.01941  loss_rpn_loc: 0.01095    time: 0.5178  last_time: 0.6203  data_time: 0.0020  last_data_time: 0.0026   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:01 d2.utils.events]: \u001b[0m eta: 1:09:50  iter: 2059  total_loss: 0.5345  loss_cls: 0.1642  loss_box_reg: 0.3515  loss_rpn_cls: 0.0327  loss_rpn_loc: 0.009227    time: 0.5181  last_time: 0.5612  data_time: 0.0019  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:12 d2.utils.events]: \u001b[0m eta: 1:09:47  iter: 2079  total_loss: 0.541  loss_cls: 0.158  loss_box_reg: 0.3682  loss_rpn_cls: 0.01464  loss_rpn_loc: 0.009256    time: 0.5185  last_time: 0.6307  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:23 d2.utils.events]: \u001b[0m eta: 1:09:30  iter: 2099  total_loss: 0.4593  loss_cls: 0.1527  loss_box_reg: 0.2719  loss_rpn_cls: 0.008829  loss_rpn_loc: 0.006763    time: 0.5186  last_time: 0.4358  data_time: 0.0019  last_data_time: 0.0028   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:33 d2.utils.events]: \u001b[0m eta: 1:09:17  iter: 2119  total_loss: 0.5802  loss_cls: 0.1776  loss_box_reg: 0.3347  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.01265    time: 0.5186  last_time: 0.5594  data_time: 0.0015  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:44 d2.utils.events]: \u001b[0m eta: 1:09:09  iter: 2139  total_loss: 0.4976  loss_cls: 0.1741  loss_box_reg: 0.3237  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.008165    time: 0.5188  last_time: 0.5014  data_time: 0.0015  last_data_time: 0.0020   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:11:55 d2.utils.events]: \u001b[0m eta: 1:08:59  iter: 2159  total_loss: 0.6635  loss_cls: 0.2196  loss_box_reg: 0.408  loss_rpn_cls: 0.02259  loss_rpn_loc: 0.01082    time: 0.5189  last_time: 0.5570  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:06 d2.utils.events]: \u001b[0m eta: 1:08:54  iter: 2179  total_loss: 0.5325  loss_cls: 0.1756  loss_box_reg: 0.327  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.01365    time: 0.5192  last_time: 0.4743  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:17 d2.utils.events]: \u001b[0m eta: 1:08:50  iter: 2199  total_loss: 0.6021  loss_cls: 0.1913  loss_box_reg: 0.3708  loss_rpn_cls: 0.02831  loss_rpn_loc: 0.01088    time: 0.5194  last_time: 0.5606  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:28 d2.utils.events]: \u001b[0m eta: 1:08:47  iter: 2219  total_loss: 0.4988  loss_cls: 0.182  loss_box_reg: 0.2958  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.00662    time: 0.5197  last_time: 0.5314  data_time: 0.0015  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:38 d2.utils.events]: \u001b[0m eta: 1:08:36  iter: 2239  total_loss: 0.549  loss_cls: 0.161  loss_box_reg: 0.3202  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.008428    time: 0.5196  last_time: 0.4106  data_time: 0.0014  last_data_time: 0.0007   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:48 d2.utils.events]: \u001b[0m eta: 1:08:27  iter: 2259  total_loss: 0.5636  loss_cls: 0.185  loss_box_reg: 0.3514  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.01446    time: 0.5196  last_time: 0.5481  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:12:59 d2.utils.events]: \u001b[0m eta: 1:08:16  iter: 2279  total_loss: 0.6233  loss_cls: 0.2073  loss_box_reg: 0.4122  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.009721    time: 0.5197  last_time: 0.5722  data_time: 0.0014  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:13:10 d2.utils.events]: \u001b[0m eta: 1:08:05  iter: 2299  total_loss: 0.5185  loss_cls: 0.1438  loss_box_reg: 0.3445  loss_rpn_cls: 0.00943  loss_rpn_loc: 0.008731    time: 0.5198  last_time: 0.5550  data_time: 0.0016  last_data_time: 0.0005   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:13:20 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 2319  total_loss: 0.5992  loss_cls: 0.183  loss_box_reg: 0.389  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.01293    time: 0.5199  last_time: 0.6344  data_time: 0.0017  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:13:31 d2.utils.events]: \u001b[0m eta: 1:07:48  iter: 2339  total_loss: 0.6085  loss_cls: 0.188  loss_box_reg: 0.3762  loss_rpn_cls: 0.02148  loss_rpn_loc: 0.012    time: 0.5200  last_time: 0.4767  data_time: 0.0015  last_data_time: 0.0024   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:13:41 d2.utils.events]: \u001b[0m eta: 1:07:37  iter: 2359  total_loss: 0.6326  loss_cls: 0.2311  loss_box_reg: 0.3807  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.01218    time: 0.5200  last_time: 0.5390  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:13:52 d2.utils.events]: \u001b[0m eta: 1:07:30  iter: 2379  total_loss: 0.49  loss_cls: 0.1992  loss_box_reg: 0.3129  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.007827    time: 0.5200  last_time: 0.3897  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:03 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 2399  total_loss: 0.5488  loss_cls: 0.1734  loss_box_reg: 0.3283  loss_rpn_cls: 0.01145  loss_rpn_loc: 0.006541    time: 0.5202  last_time: 0.5333  data_time: 0.0016  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:13 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 2419  total_loss: 0.6669  loss_cls: 0.2155  loss_box_reg: 0.3643  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.0157    time: 0.5203  last_time: 0.5737  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:24 d2.utils.events]: \u001b[0m eta: 1:07:14  iter: 2439  total_loss: 0.5644  loss_cls: 0.1832  loss_box_reg: 0.3591  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.008505    time: 0.5206  last_time: 0.3915  data_time: 0.0016  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:35 d2.utils.events]: \u001b[0m eta: 1:07:08  iter: 2459  total_loss: 0.4883  loss_cls: 0.1505  loss_box_reg: 0.3239  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.01153    time: 0.5207  last_time: 0.5092  data_time: 0.0016  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:46 d2.utils.events]: \u001b[0m eta: 1:06:58  iter: 2479  total_loss: 0.5111  loss_cls: 0.161  loss_box_reg: 0.3358  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.008872    time: 0.5209  last_time: 0.6472  data_time: 0.0015  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:14:57 d2.utils.events]: \u001b[0m eta: 1:06:53  iter: 2499  total_loss: 0.6318  loss_cls: 0.1902  loss_box_reg: 0.3422  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.01387    time: 0.5210  last_time: 0.5051  data_time: 0.0015  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:15:07 d2.utils.events]: \u001b[0m eta: 1:06:44  iter: 2519  total_loss: 0.7536  loss_cls: 0.2338  loss_box_reg: 0.3807  loss_rpn_cls: 0.0255  loss_rpn_loc: 0.01745    time: 0.5211  last_time: 0.5201  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:15:18 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 2539  total_loss: 0.512  loss_cls: 0.1488  loss_box_reg: 0.3255  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.01043    time: 0.5213  last_time: 0.5707  data_time: 0.0019  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:15:29 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 2559  total_loss: 0.6389  loss_cls: 0.1997  loss_box_reg: 0.4042  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.01728    time: 0.5214  last_time: 0.6084  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:15:40 d2.utils.events]: \u001b[0m eta: 1:06:11  iter: 2579  total_loss: 0.6994  loss_cls: 0.2017  loss_box_reg: 0.4074  loss_rpn_cls: 0.02247  loss_rpn_loc: 0.01532    time: 0.5216  last_time: 0.5320  data_time: 0.0015  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:15:50 d2.utils.events]: \u001b[0m eta: 1:06:02  iter: 2599  total_loss: 0.7008  loss_cls: 0.2179  loss_box_reg: 0.4193  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.018    time: 0.5217  last_time: 0.6313  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:01 d2.utils.events]: \u001b[0m eta: 1:05:58  iter: 2619  total_loss: 0.527  loss_cls: 0.1706  loss_box_reg: 0.3483  loss_rpn_cls: 0.01151  loss_rpn_loc: 0.005616    time: 0.5218  last_time: 0.5114  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:11 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 2639  total_loss: 0.4832  loss_cls: 0.1404  loss_box_reg: 0.308  loss_rpn_cls: 0.00945  loss_rpn_loc: 0.006423    time: 0.5217  last_time: 0.4770  data_time: 0.0015  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:22 d2.utils.events]: \u001b[0m eta: 1:05:29  iter: 2659  total_loss: 0.6053  loss_cls: 0.1958  loss_box_reg: 0.3438  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.008562    time: 0.5217  last_time: 0.5356  data_time: 0.0014  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:33 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 2679  total_loss: 0.5109  loss_cls: 0.1693  loss_box_reg: 0.289  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.01085    time: 0.5218  last_time: 0.5582  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:43 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 2699  total_loss: 0.5912  loss_cls: 0.2012  loss_box_reg: 0.361  loss_rpn_cls: 0.01396  loss_rpn_loc: 0.0111    time: 0.5219  last_time: 0.6405  data_time: 0.0017  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:16:54 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 2719  total_loss: 0.6165  loss_cls: 0.1976  loss_box_reg: 0.3528  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.01592    time: 0.5222  last_time: 0.5141  data_time: 0.0015  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:06 d2.utils.events]: \u001b[0m eta: 1:05:01  iter: 2739  total_loss: 0.5686  loss_cls: 0.1886  loss_box_reg: 0.3029  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.01091    time: 0.5224  last_time: 0.6137  data_time: 0.0020  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:17 d2.utils.events]: \u001b[0m eta: 1:04:51  iter: 2759  total_loss: 0.6579  loss_cls: 0.1869  loss_box_reg: 0.4411  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.01488    time: 0.5226  last_time: 0.5322  data_time: 0.0016  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:27 d2.utils.events]: \u001b[0m eta: 1:04:40  iter: 2779  total_loss: 0.5915  loss_cls: 0.1845  loss_box_reg: 0.34  loss_rpn_cls: 0.02066  loss_rpn_loc: 0.01565    time: 0.5227  last_time: 0.6163  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:38 d2.utils.events]: \u001b[0m eta: 1:04:28  iter: 2799  total_loss: 0.5687  loss_cls: 0.1916  loss_box_reg: 0.3457  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.008959    time: 0.5228  last_time: 0.6127  data_time: 0.0016  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:49 d2.utils.events]: \u001b[0m eta: 1:04:18  iter: 2819  total_loss: 0.6491  loss_cls: 0.2153  loss_box_reg: 0.3833  loss_rpn_cls: 0.01542  loss_rpn_loc: 0.01843    time: 0.5229  last_time: 0.6104  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:17:59 d2.utils.events]: \u001b[0m eta: 1:04:08  iter: 2839  total_loss: 0.5263  loss_cls: 0.1785  loss_box_reg: 0.3269  loss_rpn_cls: 0.02155  loss_rpn_loc: 0.009826    time: 0.5229  last_time: 0.6135  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:18:10 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 2859  total_loss: 0.5256  loss_cls: 0.1934  loss_box_reg: 0.3103  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.00943    time: 0.5230  last_time: 0.5050  data_time: 0.0015  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:18:21 d2.utils.events]: \u001b[0m eta: 1:03:48  iter: 2879  total_loss: 0.4914  loss_cls: 0.1662  loss_box_reg: 0.302  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.009205    time: 0.5231  last_time: 0.4482  data_time: 0.0018  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:18:31 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 2899  total_loss: 0.4781  loss_cls: 0.1538  loss_box_reg: 0.3137  loss_rpn_cls: 0.01409  loss_rpn_loc: 0.0122    time: 0.5230  last_time: 0.5638  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:18:41 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 2919  total_loss: 0.789  loss_cls: 0.2569  loss_box_reg: 0.4661  loss_rpn_cls: 0.02104  loss_rpn_loc: 0.01346    time: 0.5229  last_time: 0.5621  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:18:52 d2.utils.events]: \u001b[0m eta: 1:03:13  iter: 2939  total_loss: 0.513  loss_cls: 0.1625  loss_box_reg: 0.3237  loss_rpn_cls: 0.01451  loss_rpn_loc: 0.009352    time: 0.5230  last_time: 0.3829  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:02 d2.utils.events]: \u001b[0m eta: 1:03:01  iter: 2959  total_loss: 0.5717  loss_cls: 0.1716  loss_box_reg: 0.3359  loss_rpn_cls: 0.007524  loss_rpn_loc: 0.008963    time: 0.5230  last_time: 0.4379  data_time: 0.0017  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:13 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 2979  total_loss: 0.4916  loss_cls: 0.1589  loss_box_reg: 0.3121  loss_rpn_cls: 0.01341  loss_rpn_loc: 0.01137    time: 0.5230  last_time: 0.5145  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:23 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 2999  total_loss: 0.4388  loss_cls: 0.1348  loss_box_reg: 0.2934  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.006654    time: 0.5230  last_time: 0.5306  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:34 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 3019  total_loss: 0.5942  loss_cls: 0.1836  loss_box_reg: 0.3531  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.0148    time: 0.5232  last_time: 0.4791  data_time: 0.0016  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:45 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 3039  total_loss: 0.7133  loss_cls: 0.198  loss_box_reg: 0.3623  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.009372    time: 0.5233  last_time: 0.5846  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:19:56 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 3059  total_loss: 0.5453  loss_cls: 0.1701  loss_box_reg: 0.3366  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.0109    time: 0.5235  last_time: 0.5630  data_time: 0.0015  last_data_time: 0.0021   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:20:07 d2.utils.events]: \u001b[0m eta: 1:01:46  iter: 3079  total_loss: 0.6022  loss_cls: 0.1829  loss_box_reg: 0.3528  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.008761    time: 0.5236  last_time: 0.5582  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:20:18 d2.utils.events]: \u001b[0m eta: 1:01:41  iter: 3099  total_loss: 0.5155  loss_cls: 0.1943  loss_box_reg: 0.3317  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.01218    time: 0.5238  last_time: 0.6075  data_time: 0.0017  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:20:29 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 3119  total_loss: 0.6643  loss_cls: 0.2208  loss_box_reg: 0.3411  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.01005    time: 0.5240  last_time: 0.6099  data_time: 0.0015  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:20:40 d2.utils.events]: \u001b[0m eta: 1:01:27  iter: 3139  total_loss: 0.6582  loss_cls: 0.2269  loss_box_reg: 0.3549  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.01134    time: 0.5242  last_time: 0.6796  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:20:51 d2.utils.events]: \u001b[0m eta: 1:01:16  iter: 3159  total_loss: 0.5542  loss_cls: 0.1696  loss_box_reg: 0.3422  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.01093    time: 0.5242  last_time: 0.4768  data_time: 0.0017  last_data_time: 0.0020   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:02 d2.utils.events]: \u001b[0m eta: 1:01:05  iter: 3179  total_loss: 0.4636  loss_cls: 0.1563  loss_box_reg: 0.2524  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.009296    time: 0.5243  last_time: 0.5020  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:12 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 3199  total_loss: 0.5377  loss_cls: 0.1669  loss_box_reg: 0.2899  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.008639    time: 0.5242  last_time: 0.4398  data_time: 0.0015  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:23 d2.utils.events]: \u001b[0m eta: 1:00:39  iter: 3219  total_loss: 0.4623  loss_cls: 0.1434  loss_box_reg: 0.2448  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.005446    time: 0.5244  last_time: 0.5350  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:33 d2.utils.events]: \u001b[0m eta: 1:00:29  iter: 3239  total_loss: 0.5765  loss_cls: 0.1909  loss_box_reg: 0.3192  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.01324    time: 0.5244  last_time: 0.4090  data_time: 0.0016  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:44 d2.utils.events]: \u001b[0m eta: 1:00:19  iter: 3259  total_loss: 0.5626  loss_cls: 0.1569  loss_box_reg: 0.3346  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.009611    time: 0.5245  last_time: 0.6103  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:21:55 d2.utils.events]: \u001b[0m eta: 1:00:10  iter: 3279  total_loss: 0.6129  loss_cls: 0.1905  loss_box_reg: 0.311  loss_rpn_cls: 0.02563  loss_rpn_loc: 0.01665    time: 0.5246  last_time: 0.5646  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:06 d2.utils.events]: \u001b[0m eta: 0:59:57  iter: 3299  total_loss: 0.4701  loss_cls: 0.1595  loss_box_reg: 0.2661  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.008625    time: 0.5246  last_time: 0.4807  data_time: 0.0017  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:17 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 3319  total_loss: 0.518  loss_cls: 0.1559  loss_box_reg: 0.3053  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.009389    time: 0.5248  last_time: 0.5659  data_time: 0.0015  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:27 d2.utils.events]: \u001b[0m eta: 0:59:39  iter: 3339  total_loss: 0.5115  loss_cls: 0.1677  loss_box_reg: 0.3004  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.01167    time: 0.5248  last_time: 0.4511  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:37 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 3359  total_loss: 0.49  loss_cls: 0.1741  loss_box_reg: 0.2865  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.007838    time: 0.5246  last_time: 0.5681  data_time: 0.0015  last_data_time: 0.0006   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:48 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 3379  total_loss: 0.5822  loss_cls: 0.2134  loss_box_reg: 0.3043  loss_rpn_cls: 0.01463  loss_rpn_loc: 0.009253    time: 0.5247  last_time: 0.6202  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:22:59 d2.utils.events]: \u001b[0m eta: 0:59:04  iter: 3399  total_loss: 0.5314  loss_cls: 0.1717  loss_box_reg: 0.3006  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.01197    time: 0.5248  last_time: 0.4921  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:23:10 d2.utils.events]: \u001b[0m eta: 0:58:56  iter: 3419  total_loss: 0.5161  loss_cls: 0.1598  loss_box_reg: 0.3333  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.008856    time: 0.5250  last_time: 0.5415  data_time: 0.0019  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:23:21 d2.utils.events]: \u001b[0m eta: 0:58:45  iter: 3439  total_loss: 0.5403  loss_cls: 0.1846  loss_box_reg: 0.2792  loss_rpn_cls: 0.01977  loss_rpn_loc: 0.0131    time: 0.5251  last_time: 0.5439  data_time: 0.0016  last_data_time: 0.0009   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:23:32 d2.utils.events]: \u001b[0m eta: 0:58:38  iter: 3459  total_loss: 0.5427  loss_cls: 0.1725  loss_box_reg: 0.2686  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.01332    time: 0.5253  last_time: 0.5638  data_time: 0.0019  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:23:43 d2.utils.events]: \u001b[0m eta: 0:58:29  iter: 3479  total_loss: 0.3785  loss_cls: 0.1259  loss_box_reg: 0.2362  loss_rpn_cls: 0.01337  loss_rpn_loc: 0.01023    time: 0.5254  last_time: 0.5747  data_time: 0.0016  last_data_time: 0.0020   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:23:54 d2.utils.events]: \u001b[0m eta: 0:58:16  iter: 3499  total_loss: 0.5525  loss_cls: 0.1512  loss_box_reg: 0.3085  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.01591    time: 0.5255  last_time: 0.5155  data_time: 0.0017  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:04 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 3519  total_loss: 0.4491  loss_cls: 0.1606  loss_box_reg: 0.2621  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.0112    time: 0.5256  last_time: 0.5107  data_time: 0.0015  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:15 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 3539  total_loss: 0.494  loss_cls: 0.1552  loss_box_reg: 0.3047  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01859    time: 0.5255  last_time: 0.5006  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:26 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 3559  total_loss: 0.5548  loss_cls: 0.1853  loss_box_reg: 0.3309  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.01102    time: 0.5257  last_time: 0.6086  data_time: 0.0016  last_data_time: 0.0021   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:37 d2.utils.events]: \u001b[0m eta: 0:57:31  iter: 3579  total_loss: 0.6231  loss_cls: 0.1965  loss_box_reg: 0.3897  loss_rpn_cls: 0.02365  loss_rpn_loc: 0.0195    time: 0.5259  last_time: 0.4276  data_time: 0.0017  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:48 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 3599  total_loss: 0.5537  loss_cls: 0.168  loss_box_reg: 0.3218  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.01197    time: 0.5259  last_time: 0.5594  data_time: 0.0018  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:24:59 d2.utils.events]: \u001b[0m eta: 0:57:12  iter: 3619  total_loss: 0.5078  loss_cls: 0.1388  loss_box_reg: 0.3294  loss_rpn_cls: 0.009459  loss_rpn_loc: 0.01051    time: 0.5260  last_time: 0.4780  data_time: 0.0018  last_data_time: 0.0029   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:25:10 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 3639  total_loss: 0.5956  loss_cls: 0.1775  loss_box_reg: 0.3707  loss_rpn_cls: 0.01291  loss_rpn_loc: 0.008592    time: 0.5261  last_time: 0.6199  data_time: 0.0017  last_data_time: 0.0036   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:25:20 d2.utils.events]: \u001b[0m eta: 0:57:03  iter: 3659  total_loss: 0.6521  loss_cls: 0.2146  loss_box_reg: 0.412  loss_rpn_cls: 0.03024  loss_rpn_loc: 0.02116    time: 0.5261  last_time: 0.5751  data_time: 0.0028  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:25:31 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 3679  total_loss: 0.5592  loss_cls: 0.2175  loss_box_reg: 0.3278  loss_rpn_cls: 0.01376  loss_rpn_loc: 0.01313    time: 0.5262  last_time: 0.6109  data_time: 0.0017  last_data_time: 0.0033   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:25:41 d2.utils.events]: \u001b[0m eta: 0:56:39  iter: 3699  total_loss: 0.6498  loss_cls: 0.1938  loss_box_reg: 0.3384  loss_rpn_cls: 0.02069  loss_rpn_loc: 0.009645    time: 0.5261  last_time: 0.5162  data_time: 0.0019  last_data_time: 0.0028   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:25:52 d2.utils.events]: \u001b[0m eta: 0:56:24  iter: 3719  total_loss: 0.5558  loss_cls: 0.1826  loss_box_reg: 0.3244  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.01246    time: 0.5262  last_time: 0.6476  data_time: 0.0018  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:02 d2.utils.events]: \u001b[0m eta: 0:56:07  iter: 3739  total_loss: 0.5973  loss_cls: 0.2101  loss_box_reg: 0.3497  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.01611    time: 0.5262  last_time: 0.4522  data_time: 0.0017  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:14 d2.utils.events]: \u001b[0m eta: 0:55:56  iter: 3759  total_loss: 0.5831  loss_cls: 0.1598  loss_box_reg: 0.3891  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.01191    time: 0.5263  last_time: 0.4658  data_time: 0.0017  last_data_time: 0.0027   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:24 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 3779  total_loss: 0.5887  loss_cls: 0.1668  loss_box_reg: 0.3446  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.01308    time: 0.5263  last_time: 0.5406  data_time: 0.0017  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:35 d2.utils.events]: \u001b[0m eta: 0:55:42  iter: 3799  total_loss: 0.5876  loss_cls: 0.1675  loss_box_reg: 0.3306  loss_rpn_cls: 0.02085  loss_rpn_loc: 0.01303    time: 0.5266  last_time: 0.5314  data_time: 0.0016  last_data_time: 0.0020   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:46 d2.utils.events]: \u001b[0m eta: 0:55:29  iter: 3819  total_loss: 0.6798  loss_cls: 0.2214  loss_box_reg: 0.3768  loss_rpn_cls: 0.01339  loss_rpn_loc: 0.01149    time: 0.5266  last_time: 0.6169  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:26:57 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 3839  total_loss: 0.6049  loss_cls: 0.1729  loss_box_reg: 0.4037  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.008388    time: 0.5267  last_time: 0.5772  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:27:08 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 3859  total_loss: 0.4892  loss_cls: 0.1508  loss_box_reg: 0.3143  loss_rpn_cls: 0.01035  loss_rpn_loc: 0.009536    time: 0.5267  last_time: 0.4525  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:27:18 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 3879  total_loss: 0.5753  loss_cls: 0.1589  loss_box_reg: 0.3857  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.009256    time: 0.5267  last_time: 0.5692  data_time: 0.0016  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:27:29 d2.utils.events]: \u001b[0m eta: 0:54:51  iter: 3899  total_loss: 0.6625  loss_cls: 0.2228  loss_box_reg: 0.3633  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.02182    time: 0.5268  last_time: 0.5710  data_time: 0.0018  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:27:40 d2.utils.events]: \u001b[0m eta: 0:54:43  iter: 3919  total_loss: 0.6532  loss_cls: 0.1935  loss_box_reg: 0.394  loss_rpn_cls: 0.01205  loss_rpn_loc: 0.009556    time: 0.5269  last_time: 0.6170  data_time: 0.0016  last_data_time: 0.0036   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:27:51 d2.utils.events]: \u001b[0m eta: 0:54:33  iter: 3939  total_loss: 0.5452  loss_cls: 0.1742  loss_box_reg: 0.3565  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.01303    time: 0.5270  last_time: 0.7027  data_time: 0.0016  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:02 d2.utils.events]: \u001b[0m eta: 0:54:24  iter: 3959  total_loss: 0.4919  loss_cls: 0.1448  loss_box_reg: 0.3111  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.01014    time: 0.5271  last_time: 0.4717  data_time: 0.0015  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:13 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 3979  total_loss: 0.5257  loss_cls: 0.1854  loss_box_reg: 0.3216  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.01287    time: 0.5272  last_time: 0.6146  data_time: 0.0016  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:24 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 3999  total_loss: 0.5002  loss_cls: 0.1442  loss_box_reg: 0.2915  loss_rpn_cls: 0.005957  loss_rpn_loc: 0.005028    time: 0.5273  last_time: 0.5697  data_time: 0.0019  last_data_time: 0.0027   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:35 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 4019  total_loss: 0.5189  loss_cls: 0.1635  loss_box_reg: 0.3129  loss_rpn_cls: 0.02288  loss_rpn_loc: 0.009537    time: 0.5274  last_time: 0.6152  data_time: 0.0017  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:46 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 4039  total_loss: 0.6907  loss_cls: 0.2295  loss_box_reg: 0.381  loss_rpn_cls: 0.01627  loss_rpn_loc: 0.01358    time: 0.5276  last_time: 0.5703  data_time: 0.0021  last_data_time: 0.0028   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:28:57 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 4059  total_loss: 0.5023  loss_cls: 0.1361  loss_box_reg: 0.2968  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.00718    time: 0.5277  last_time: 0.5582  data_time: 0.0021  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:29:08 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 4079  total_loss: 0.5163  loss_cls: 0.1623  loss_box_reg: 0.3227  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.01342    time: 0.5278  last_time: 0.5742  data_time: 0.0019  last_data_time: 0.0021   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:29:20 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 4099  total_loss: 0.4894  loss_cls: 0.1435  loss_box_reg: 0.3097  loss_rpn_cls: 0.008272  loss_rpn_loc: 0.006834    time: 0.5280  last_time: 0.6455  data_time: 0.0021  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:29:30 d2.utils.events]: \u001b[0m eta: 0:53:11  iter: 4119  total_loss: 0.5328  loss_cls: 0.1523  loss_box_reg: 0.33  loss_rpn_cls: 0.01295  loss_rpn_loc: 0.008645    time: 0.5281  last_time: 0.5063  data_time: 0.0021  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:29:41 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 4139  total_loss: 0.4671  loss_cls: 0.1378  loss_box_reg: 0.3234  loss_rpn_cls: 0.009421  loss_rpn_loc: 0.007539    time: 0.5281  last_time: 0.5492  data_time: 0.0021  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:29:53 d2.utils.events]: \u001b[0m eta: 0:52:49  iter: 4159  total_loss: 0.5827  loss_cls: 0.2043  loss_box_reg: 0.3094  loss_rpn_cls: 0.01996  loss_rpn_loc: 0.0154    time: 0.5283  last_time: 0.5756  data_time: 0.0020  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:03 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 4179  total_loss: 0.4753  loss_cls: 0.1931  loss_box_reg: 0.2939  loss_rpn_cls: 0.0141  loss_rpn_loc: 0.008762    time: 0.5284  last_time: 0.5747  data_time: 0.0021  last_data_time: 0.0029   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:14 d2.utils.events]: \u001b[0m eta: 0:52:35  iter: 4199  total_loss: 0.6038  loss_cls: 0.1946  loss_box_reg: 0.3716  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.008649    time: 0.5285  last_time: 0.5151  data_time: 0.0020  last_data_time: 0.0024   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:25 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 4219  total_loss: 0.587  loss_cls: 0.1797  loss_box_reg: 0.3643  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.01614    time: 0.5286  last_time: 0.5969  data_time: 0.0019  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:37 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 4239  total_loss: 0.512  loss_cls: 0.1598  loss_box_reg: 0.2941  loss_rpn_cls: 0.01176  loss_rpn_loc: 0.008129    time: 0.5288  last_time: 0.5658  data_time: 0.0018  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:47 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 4259  total_loss: 0.4987  loss_cls: 0.1606  loss_box_reg: 0.3034  loss_rpn_cls: 0.01741  loss_rpn_loc: 0.01461    time: 0.5288  last_time: 0.4980  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:30:59 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 4279  total_loss: 0.6268  loss_cls: 0.18  loss_box_reg: 0.3267  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.01114    time: 0.5289  last_time: 0.5045  data_time: 0.0019  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:31:09 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 4299  total_loss: 0.5218  loss_cls: 0.1856  loss_box_reg: 0.3611  loss_rpn_cls: 0.007508  loss_rpn_loc: 0.008671    time: 0.5290  last_time: 0.5118  data_time: 0.0018  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:31:20 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 4319  total_loss: 0.5333  loss_cls: 0.1774  loss_box_reg: 0.2932  loss_rpn_cls: 0.01685  loss_rpn_loc: 0.0137    time: 0.5291  last_time: 0.4697  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:31:31 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 4339  total_loss: 0.5982  loss_cls: 0.1891  loss_box_reg: 0.3418  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.01408    time: 0.5291  last_time: 0.4940  data_time: 0.0016  last_data_time: 0.0014   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:31:42 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 4359  total_loss: 0.6403  loss_cls: 0.1905  loss_box_reg: 0.3909  loss_rpn_cls: 0.0175  loss_rpn_loc: 0.009791    time: 0.5292  last_time: 0.5045  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:31:53 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 4379  total_loss: 0.5301  loss_cls: 0.1633  loss_box_reg: 0.348  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.008952    time: 0.5292  last_time: 0.5447  data_time: 0.0018  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:03 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 4399  total_loss: 0.514  loss_cls: 0.1468  loss_box_reg: 0.3309  loss_rpn_cls: 0.009198  loss_rpn_loc: 0.00745    time: 0.5292  last_time: 0.5171  data_time: 0.0018  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:15 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 4419  total_loss: 0.6289  loss_cls: 0.1872  loss_box_reg: 0.387  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.009998    time: 0.5294  last_time: 0.6626  data_time: 0.0022  last_data_time: 0.0021   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:26 d2.utils.events]: \u001b[0m eta: 0:50:29  iter: 4439  total_loss: 0.6313  loss_cls: 0.1906  loss_box_reg: 0.3875  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.01467    time: 0.5296  last_time: 0.6243  data_time: 0.0017  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:37 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 4459  total_loss: 0.6196  loss_cls: 0.194  loss_box_reg: 0.3194  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.01298    time: 0.5297  last_time: 0.4853  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:48 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 4479  total_loss: 0.6337  loss_cls: 0.223  loss_box_reg: 0.3525  loss_rpn_cls: 0.009458  loss_rpn_loc: 0.007599    time: 0.5297  last_time: 0.4184  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:32:59 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 4499  total_loss: 0.7948  loss_cls: 0.254  loss_box_reg: 0.4302  loss_rpn_cls: 0.02842  loss_rpn_loc: 0.0224    time: 0.5297  last_time: 0.5091  data_time: 0.0016  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:33:09 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 4519  total_loss: 0.5794  loss_cls: 0.1769  loss_box_reg: 0.3135  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.01004    time: 0.5297  last_time: 0.5707  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:33:20 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 4539  total_loss: 0.5042  loss_cls: 0.1474  loss_box_reg: 0.3114  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.006346    time: 0.5298  last_time: 0.4816  data_time: 0.0017  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:33:31 d2.utils.events]: \u001b[0m eta: 0:49:23  iter: 4559  total_loss: 0.5897  loss_cls: 0.1851  loss_box_reg: 0.349  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.0114    time: 0.5299  last_time: 0.6199  data_time: 0.0016  last_data_time: 0.0011   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:33:43 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 4579  total_loss: 0.6  loss_cls: 0.1946  loss_box_reg: 0.3618  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.01507    time: 0.5301  last_time: 0.5610  data_time: 0.0015  last_data_time: 0.0012   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:33:53 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 4599  total_loss: 0.6861  loss_cls: 0.2017  loss_box_reg: 0.3915  loss_rpn_cls: 0.02636  loss_rpn_loc: 0.01709    time: 0.5301  last_time: 0.5141  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:04 d2.utils.events]: \u001b[0m eta: 0:49:01  iter: 4619  total_loss: 0.5291  loss_cls: 0.1894  loss_box_reg: 0.3066  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.009787    time: 0.5302  last_time: 0.4822  data_time: 0.0018  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:15 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 4639  total_loss: 0.6167  loss_cls: 0.201  loss_box_reg: 0.4113  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.01288    time: 0.5303  last_time: 0.6154  data_time: 0.0017  last_data_time: 0.0027   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:26 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 4659  total_loss: 0.5879  loss_cls: 0.1897  loss_box_reg: 0.375  loss_rpn_cls: 0.01508  loss_rpn_loc: 0.01173    time: 0.5304  last_time: 0.5591  data_time: 0.0016  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:37 d2.utils.events]: \u001b[0m eta: 0:48:28  iter: 4679  total_loss: 0.5032  loss_cls: 0.16  loss_box_reg: 0.3039  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.01011    time: 0.5303  last_time: 0.5141  data_time: 0.0015  last_data_time: 0.0023   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:48 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 4699  total_loss: 0.5868  loss_cls: 0.189  loss_box_reg: 0.3537  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.01161    time: 0.5304  last_time: 0.6238  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:34:58 d2.utils.events]: \u001b[0m eta: 0:48:16  iter: 4719  total_loss: 0.521  loss_cls: 0.1589  loss_box_reg: 0.3189  loss_rpn_cls: 0.01236  loss_rpn_loc: 0.007492    time: 0.5304  last_time: 0.6488  data_time: 0.0016  last_data_time: 0.0022   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:35:09 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 4739  total_loss: 0.6927  loss_cls: 0.2288  loss_box_reg: 0.3944  loss_rpn_cls: 0.03117  loss_rpn_loc: 0.02262    time: 0.5304  last_time: 0.5790  data_time: 0.0017  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:35:19 d2.utils.events]: \u001b[0m eta: 0:47:40  iter: 4759  total_loss: 0.4956  loss_cls: 0.1478  loss_box_reg: 0.3345  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.007572    time: 0.5303  last_time: 0.5176  data_time: 0.0016  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:35:30 d2.utils.events]: \u001b[0m eta: 0:47:47  iter: 4779  total_loss: 0.6556  loss_cls: 0.2184  loss_box_reg: 0.3469  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.02066    time: 0.5304  last_time: 0.6151  data_time: 0.0017  last_data_time: 0.0015   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:35:41 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 4799  total_loss: 0.4306  loss_cls: 0.127  loss_box_reg: 0.2581  loss_rpn_cls: 0.009982  loss_rpn_loc: 0.007426    time: 0.5304  last_time: 0.6505  data_time: 0.0016  last_data_time: 0.0018   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:35:52 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 4819  total_loss: 0.6646  loss_cls: 0.1852  loss_box_reg: 0.4082  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.01382    time: 0.5305  last_time: 0.5120  data_time: 0.0016  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:02 d2.utils.events]: \u001b[0m eta: 0:47:01  iter: 4839  total_loss: 0.5041  loss_cls: 0.1663  loss_box_reg: 0.2821  loss_rpn_cls: 0.01622  loss_rpn_loc: 0.009926    time: 0.5305  last_time: 0.5998  data_time: 0.0016  last_data_time: 0.0017   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:13 d2.utils.events]: \u001b[0m eta: 0:46:53  iter: 4859  total_loss: 0.5772  loss_cls: 0.1863  loss_box_reg: 0.3629  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.009653    time: 0.5304  last_time: 0.6035  data_time: 0.0015  last_data_time: 0.0010   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:23 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 4879  total_loss: 0.5691  loss_cls: 0.1812  loss_box_reg: 0.3831  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.01369    time: 0.5304  last_time: 0.4984  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:34 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 4899  total_loss: 0.5204  loss_cls: 0.1694  loss_box_reg: 0.2623  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.009314    time: 0.5305  last_time: 0.5089  data_time: 0.0017  last_data_time: 0.0021   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:45 d2.utils.events]: \u001b[0m eta: 0:46:13  iter: 4919  total_loss: 0.527  loss_cls: 0.1652  loss_box_reg: 0.3278  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.01363    time: 0.5305  last_time: 0.5112  data_time: 0.0017  last_data_time: 0.0016   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:36:55 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 4939  total_loss: 0.6051  loss_cls: 0.1807  loss_box_reg: 0.4017  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.01712    time: 0.5304  last_time: 0.4804  data_time: 0.0018  last_data_time: 0.0025   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:37:06 d2.utils.events]: \u001b[0m eta: 0:45:48  iter: 4959  total_loss: 0.5792  loss_cls: 0.1874  loss_box_reg: 0.3417  loss_rpn_cls: 0.01674  loss_rpn_loc: 0.01347    time: 0.5304  last_time: 0.4808  data_time: 0.0016  last_data_time: 0.0008   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:37:17 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 4979  total_loss: 0.5894  loss_cls: 0.2024  loss_box_reg: 0.3442  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.01288    time: 0.5305  last_time: 0.5659  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[32m[07/02 18:37:28 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 4999  total_loss: 0.4784  loss_cls: 0.1451  loss_box_reg: 0.3169  loss_rpn_cls: 0.006259  loss_rpn_loc: 0.007404    time: 0.5306  last_time: 0.5064  data_time: 0.0018  last_data_time: 0.0019   lr: 0.00025  max_mem: 4389M\n",
      "\u001b[4m\u001b[5m\u001b[31mERROR\u001b[0m \u001b[32m[07/02 18:37:29 d2.engine.train_loop]: \u001b[0mException during training:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\detectron2\\engine\\train_loop.py\", line 156, in train\n",
      "    self.after_step()\n",
      "  File \"c:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\detectron2\\engine\\train_loop.py\", line 190, in after_step\n",
      "    h.after_step()\n",
      "  File \"C:\\Users\\dawoo\\AppData\\Local\\Temp\\ipykernel_12180\\1120194095.py\", line 53, in after_step\n",
      "    self.trainer.checkpointer.save(checkpoint_path)\n",
      "  File \"c:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fvcore\\common\\checkpoint.py\", line 123, in save\n",
      "    assert os.path.basename(save_file) == basename, basename\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: ./output\\model_checkpoint_iter_5000.pth.pth\n",
      "\u001b[32m[07/02 18:37:29 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 0:44:12 (0.5307 s / it)\n",
      "\u001b[32m[07/02 18:37:29 d2.engine.hooks]: \u001b[0mTotal training time: 0:44:14 (0:00:02 on hooks)\n",
      "\u001b[32m[07/02 18:37:29 d2.utils.events]: \u001b[0m eta: 0:45:31  iter: 5000  total_loss: 0.4997  loss_cls: 0.1451  loss_box_reg: 0.3185  loss_rpn_cls: 0.006415  loss_rpn_loc: 0.008662    time: 0.5306  last_time: 0.5129  data_time: 0.0018  last_data_time: 0.0020   lr: 0.00025  max_mem: 4389M\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "./output\\model_checkpoint_iter_5000.pth.pth",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m trainer\u001b[38;5;241m.\u001b[39mregister_hooks([custom_hook])\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Plot losses\u001b[39;00m\n\u001b[0;32m     76\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\detectron2\\engine\\defaults.py:488\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    482\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \n\u001b[0;32m    485\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[0;32m    491\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    492\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\detectron2\\engine\\train_loop.py:156\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[1;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_step()\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\detectron2\\engine\\train_loop.py:190\u001b[0m, in \u001b[0;36mTrainerBase.after_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[1;32m--> 190\u001b[0m         \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m, in \u001b[0;36mCustomHook.after_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iteration \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     52\u001b[0m     checkpoint_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mOUTPUT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_checkpoint_iter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel checkpoint saved at iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Log losses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dawoo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\fvcore\\common\\checkpoint.py:123\u001b[0m, in \u001b[0;36mCheckpointer.save\u001b[1;34m(self, name, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m basename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[0;32m    122\u001b[0m save_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir, basename)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(save_file) \u001b[38;5;241m==\u001b[39m basename, basename\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving checkpoint to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(save_file))\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_manager\u001b[38;5;241m.\u001b[39mopen(save_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[1;31mAssertionError\u001b[0m: ./output\\model_checkpoint_iter_5000.pth.pth"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from detectron2.engine import DefaultTrainer, HookBase\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.events import EventStorage, get_event_storage\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import detectron2.model_zoo as model_zoo\n",
    "\n",
    "# Register the dataset\n",
    "register_coco_instances(\"chair_train\", {}, \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection/dataset/annotations/instances_train2017.json\", \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection/dataset/images/train\")\n",
    "register_coco_instances(\"chair_val\", {}, \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection/dataset/annotations/instances_val2017.json\", \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection/dataset/images/val\")\n",
    "\n",
    "# Set up configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"chair_train\",)\n",
    "cfg.DATASETS.TEST = (\"chair_val\",)  # Validation dataset used for evaluation during training\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Use pre-trained weights\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025\n",
    "cfg.SOLVER.MAX_ITER = 10000\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Only one class (chair)\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Custom hook to save the model and log losses\n",
    "class CustomHook(HookBase):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.iterations = []\n",
    "        self.loss_cls = []\n",
    "        self.loss_box_reg = []\n",
    "        self.loss_rpn_cls = []\n",
    "        self.loss_rpn_loc = []\n",
    "        self.total_loss = []\n",
    "\n",
    "    def after_step(self):\n",
    "        iteration = self.trainer.iter\n",
    "        storage = get_event_storage()\n",
    "        \n",
    "        # Save model checkpoint every 5000 iterations\n",
    "        if iteration % 5000 == 0 and iteration > 0:\n",
    "            checkpoint_path = os.path.join(self.cfg.OUTPUT_DIR, f\"model_checkpoint_iter_{iteration}.pth\")\n",
    "            self.trainer.checkpointer.save(checkpoint_path)\n",
    "            print(f\"Model checkpoint saved at iteration {iteration} to {checkpoint_path}\")\n",
    "        \n",
    "        # Log losses\n",
    "        self.iterations.append(iteration)\n",
    "        self.loss_cls.append(storage.history(\"loss_cls\").latest())\n",
    "        self.loss_box_reg.append(storage.history(\"loss_box_reg\").latest())\n",
    "        self.loss_rpn_cls.append(storage.history(\"loss_rpn_cls\").latest())\n",
    "        self.loss_rpn_loc.append(storage.history(\"loss_rpn_loc\").latest())\n",
    "        self.total_loss.append(storage.history(\"total_loss\").latest())\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "\n",
    "# Add custom hook\n",
    "custom_hook = CustomHook(cfg)\n",
    "trainer.register_hooks([custom_hook])\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(custom_hook.iterations, custom_hook.total_loss, label='Total Loss')\n",
    "plt.plot(custom_hook.iterations, custom_hook.loss_cls, label='Classification Loss')\n",
    "plt.plot(custom_hook.iterations, custom_hook.loss_box_reg, label='Box Regression Loss')\n",
    "plt.plot(custom_hook.iterations, custom_hook.loss_rpn_cls, label='RPN Classification Loss')\n",
    "plt.plot(custom_hook.iterations, custom_hook.loss_rpn_loc, label='RPN Localization Loss')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# After training, load the final model and run inference on test images\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Evaluate the model on the validation set to get precision, recall, and mAP\n",
    "evaluator = COCOEvaluator(\"chair_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"chair_val\")\n",
    "evaluation_results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[07/02 18:52:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection_FasterRCNN/output/model_final.pth ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 18:52:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/02 18:52:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[07/02 18:52:06 d2.data.datasets.coco]: \u001b[0mLoaded 580 images in COCO format from D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection_FasterRCNN/dataset/annotations/instances_val2017.json\n",
      "\u001b[32m[07/02 18:52:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[07/02 18:52:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[07/02 18:52:06 d2.data.common]: \u001b[0mSerializing 580 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[07/02 18:52:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.93 MiB\n",
      "\u001b[32m[07/02 18:52:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 580 batches\n",
      "\u001b[32m[07/02 18:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/580. Dataloading: 0.0006 s/iter. Inference: 0.1296 s/iter. Eval: 0.0002 s/iter. Total: 0.1304 s/iter. ETA=0:01:14\n",
      "\u001b[32m[07/02 18:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 51/580. Dataloading: 0.0006 s/iter. Inference: 0.1251 s/iter. Eval: 0.0002 s/iter. Total: 0.1260 s/iter. ETA=0:01:06\n",
      "\u001b[32m[07/02 18:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 92/580. Dataloading: 0.0006 s/iter. Inference: 0.1242 s/iter. Eval: 0.0003 s/iter. Total: 0.1252 s/iter. ETA=0:01:01\n",
      "\u001b[32m[07/02 18:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 131/580. Dataloading: 0.0006 s/iter. Inference: 0.1256 s/iter. Eval: 0.0003 s/iter. Total: 0.1265 s/iter. ETA=0:00:56\n",
      "\u001b[32m[07/02 18:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 169/580. Dataloading: 0.0006 s/iter. Inference: 0.1269 s/iter. Eval: 0.0003 s/iter. Total: 0.1278 s/iter. ETA=0:00:52\n",
      "\u001b[32m[07/02 18:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 209/580. Dataloading: 0.0006 s/iter. Inference: 0.1271 s/iter. Eval: 0.0003 s/iter. Total: 0.1280 s/iter. ETA=0:00:47\n",
      "\u001b[32m[07/02 18:52:44 d2.evaluation.evaluator]: \u001b[0mInference done 248/580. Dataloading: 0.0006 s/iter. Inference: 0.1275 s/iter. Eval: 0.0003 s/iter. Total: 0.1285 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/02 18:52:49 d2.evaluation.evaluator]: \u001b[0mInference done 287/580. Dataloading: 0.0006 s/iter. Inference: 0.1277 s/iter. Eval: 0.0003 s/iter. Total: 0.1286 s/iter. ETA=0:00:37\n",
      "\u001b[32m[07/02 18:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 298/580. Dataloading: 0.0006 s/iter. Inference: 0.1417 s/iter. Eval: 0.0003 s/iter. Total: 0.1426 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/02 18:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 308/580. Dataloading: 0.0006 s/iter. Inference: 0.1547 s/iter. Eval: 0.0003 s/iter. Total: 0.1557 s/iter. ETA=0:00:42\n",
      "\u001b[32m[07/02 18:53:06 d2.evaluation.evaluator]: \u001b[0mInference done 317/580. Dataloading: 0.0006 s/iter. Inference: 0.1684 s/iter. Eval: 0.0003 s/iter. Total: 0.1693 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/02 18:53:11 d2.evaluation.evaluator]: \u001b[0mInference done 327/580. Dataloading: 0.0007 s/iter. Inference: 0.1799 s/iter. Eval: 0.0003 s/iter. Total: 0.1809 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/02 18:53:17 d2.evaluation.evaluator]: \u001b[0mInference done 338/580. Dataloading: 0.0007 s/iter. Inference: 0.1902 s/iter. Eval: 0.0003 s/iter. Total: 0.1912 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/02 18:53:22 d2.evaluation.evaluator]: \u001b[0mInference done 349/580. Dataloading: 0.0007 s/iter. Inference: 0.1996 s/iter. Eval: 0.0003 s/iter. Total: 0.2006 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/02 18:53:27 d2.evaluation.evaluator]: \u001b[0mInference done 360/580. Dataloading: 0.0007 s/iter. Inference: 0.2083 s/iter. Eval: 0.0003 s/iter. Total: 0.2093 s/iter. ETA=0:00:46\n",
      "\u001b[32m[07/02 18:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 371/580. Dataloading: 0.0007 s/iter. Inference: 0.2157 s/iter. Eval: 0.0003 s/iter. Total: 0.2167 s/iter. ETA=0:00:45\n",
      "\u001b[32m[07/02 18:53:38 d2.evaluation.evaluator]: \u001b[0mInference done 382/580. Dataloading: 0.0006 s/iter. Inference: 0.2231 s/iter. Eval: 0.0003 s/iter. Total: 0.2241 s/iter. ETA=0:00:44\n",
      "\u001b[32m[07/02 18:53:43 d2.evaluation.evaluator]: \u001b[0mInference done 393/580. Dataloading: 0.0006 s/iter. Inference: 0.2302 s/iter. Eval: 0.0003 s/iter. Total: 0.2312 s/iter. ETA=0:00:43\n",
      "\u001b[32m[07/02 18:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 404/580. Dataloading: 0.0006 s/iter. Inference: 0.2372 s/iter. Eval: 0.0003 s/iter. Total: 0.2382 s/iter. ETA=0:00:41\n",
      "\u001b[32m[07/02 18:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 415/580. Dataloading: 0.0006 s/iter. Inference: 0.2439 s/iter. Eval: 0.0003 s/iter. Total: 0.2449 s/iter. ETA=0:00:40\n",
      "\u001b[32m[07/02 18:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 426/580. Dataloading: 0.0006 s/iter. Inference: 0.2497 s/iter. Eval: 0.0003 s/iter. Total: 0.2507 s/iter. ETA=0:00:38\n",
      "\u001b[32m[07/02 18:54:04 d2.evaluation.evaluator]: \u001b[0mInference done 437/580. Dataloading: 0.0006 s/iter. Inference: 0.2556 s/iter. Eval: 0.0003 s/iter. Total: 0.2566 s/iter. ETA=0:00:36\n",
      "\u001b[32m[07/02 18:54:09 d2.evaluation.evaluator]: \u001b[0mInference done 449/580. Dataloading: 0.0006 s/iter. Inference: 0.2606 s/iter. Eval: 0.0003 s/iter. Total: 0.2616 s/iter. ETA=0:00:34\n",
      "\u001b[32m[07/02 18:54:15 d2.evaluation.evaluator]: \u001b[0mInference done 461/580. Dataloading: 0.0006 s/iter. Inference: 0.2655 s/iter. Eval: 0.0003 s/iter. Total: 0.2665 s/iter. ETA=0:00:31\n",
      "\u001b[32m[07/02 18:54:20 d2.evaluation.evaluator]: \u001b[0mInference done 472/580. Dataloading: 0.0006 s/iter. Inference: 0.2706 s/iter. Eval: 0.0003 s/iter. Total: 0.2716 s/iter. ETA=0:00:29\n",
      "\u001b[32m[07/02 18:54:25 d2.evaluation.evaluator]: \u001b[0mInference done 483/580. Dataloading: 0.0006 s/iter. Inference: 0.2750 s/iter. Eval: 0.0003 s/iter. Total: 0.2759 s/iter. ETA=0:00:26\n",
      "\u001b[32m[07/02 18:54:30 d2.evaluation.evaluator]: \u001b[0mInference done 494/580. Dataloading: 0.0006 s/iter. Inference: 0.2794 s/iter. Eval: 0.0003 s/iter. Total: 0.2803 s/iter. ETA=0:00:24\n",
      "\u001b[32m[07/02 18:54:35 d2.evaluation.evaluator]: \u001b[0mInference done 505/580. Dataloading: 0.0006 s/iter. Inference: 0.2833 s/iter. Eval: 0.0003 s/iter. Total: 0.2843 s/iter. ETA=0:00:21\n",
      "\u001b[32m[07/02 18:54:40 d2.evaluation.evaluator]: \u001b[0mInference done 516/580. Dataloading: 0.0006 s/iter. Inference: 0.2870 s/iter. Eval: 0.0003 s/iter. Total: 0.2880 s/iter. ETA=0:00:18\n",
      "\u001b[32m[07/02 18:54:45 d2.evaluation.evaluator]: \u001b[0mInference done 527/580. Dataloading: 0.0006 s/iter. Inference: 0.2906 s/iter. Eval: 0.0003 s/iter. Total: 0.2916 s/iter. ETA=0:00:15\n",
      "\u001b[32m[07/02 18:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 538/580. Dataloading: 0.0006 s/iter. Inference: 0.2942 s/iter. Eval: 0.0003 s/iter. Total: 0.2951 s/iter. ETA=0:00:12\n",
      "\u001b[32m[07/02 18:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 549/580. Dataloading: 0.0006 s/iter. Inference: 0.2977 s/iter. Eval: 0.0003 s/iter. Total: 0.2987 s/iter. ETA=0:00:09\n",
      "\u001b[32m[07/02 18:55:01 d2.evaluation.evaluator]: \u001b[0mInference done 560/580. Dataloading: 0.0006 s/iter. Inference: 0.3013 s/iter. Eval: 0.0003 s/iter. Total: 0.3022 s/iter. ETA=0:00:06\n",
      "\u001b[32m[07/02 18:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 571/580. Dataloading: 0.0006 s/iter. Inference: 0.3047 s/iter. Eval: 0.0003 s/iter. Total: 0.3056 s/iter. ETA=0:00:02\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:58.067852 (0.309683 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:02:56 (0.307221 s / iter per device, on 1 devices)\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output\\coco_instances_results.json\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.009\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.010\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.136\n",
      "\u001b[32m[07/02 18:55:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 0.531 | 2.395  | 0.020  | 0.312 | 0.644 | 0.872 |\n",
      "Evaluation Results: OrderedDict({'bbox': {'AP': 0.5313980607668649, 'AP50': 2.39522004172323, 'AP75': 0.020134903855834087, 'APs': 0.3122040616939786, 'APm': 0.6435101299655778, 'APl': 0.8724076367179444}})\n"
     ]
    }
   ],
   "source": [
    "# After training, load the final model and run inference on test images\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection_FasterRCNN/output/model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Evaluate the model on the validation set to get precision, recall, and mAP\n",
    "evaluator = COCOEvaluator(\"chair_val\", cfg, False, output_dir=cfg.OUTPUT_DIR)\n",
    "val_loader = build_detection_test_loader(cfg, \"chair_val\")\n",
    "evaluation_results = inference_on_dataset(predictor.model, val_loader, evaluator)\n",
    "print(\"Evaluation Results:\", evaluation_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the metrics data\n",
    "metrics_path = \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Training_chair_detection/output/metrics.json\"\n",
    "\n",
    "with open(metrics_path, 'r') as f:\n",
    "    metrics = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert metrics to a pandas DataFrame\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "# Extract iteration and loss values\n",
    "iterations = df_metrics['iteration']\n",
    "total_loss = df_metrics['total_loss']\n",
    "loss_cls = df_metrics['loss_cls']\n",
    "loss_box_reg = df_metrics['loss_box_reg']\n",
    "loss_rpn_cls = df_metrics['loss_rpn_cls']\n",
    "loss_rpn_loc = df_metrics['loss_rpn_loc']\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(iterations, total_loss, label='Total Loss')\n",
    "plt.plot(iterations, loss_cls, label='Classification Loss')\n",
    "plt.plot(iterations, loss_box_reg, label='Box Regression Loss')\n",
    "plt.plot(iterations, loss_rpn_cls, label='RPN Classification Loss')\n",
    "plt.plot(iterations, loss_rpn_loc, label='RPN Localization Loss')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses over Iterations')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
