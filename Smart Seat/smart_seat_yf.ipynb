{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2 import model_zoo\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def get_keypoints(result):\n",
    "    keypoints = result.keypoints.data.cpu().numpy()\n",
    "    return keypoints\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate the angle at point b given points a, b, and c.\"\"\"\n",
    "    ab = np.array(a) - np.array(b)\n",
    "    cb = np.array(c) - np.array(b)\n",
    "    dot_product = np.dot(ab, cb)\n",
    "    ab_magnitude = np.linalg.norm(ab)\n",
    "    cb_magnitude = np.linalg.norm(cb)\n",
    "    cosine_angle = dot_product / (ab_magnitude * cb_magnitude)\n",
    "    angle = np.arccos(cosine_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def classify_pose(keypoints):\n",
    "    try:\n",
    "        left_shoulder = keypoints[5][:2]\n",
    "        right_shoulder = keypoints[6][:2]\n",
    "        left_hip = keypoints[11][:2]\n",
    "        right_hip = keypoints[12][:2]\n",
    "        left_knee = keypoints[13][:2]\n",
    "        right_knee = keypoints[14][:2]\n",
    "        left_ankle = keypoints[15][:2]\n",
    "        right_ankle = keypoints[16][:2]\n",
    "    except IndexError as e:\n",
    "        print(f\"IndexError: {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "    left_hip_angle = calculate_angle(left_shoulder, left_hip, left_knee) if not np.all(left_ankle) else 180\n",
    "    right_hip_angle = calculate_angle(right_shoulder, right_hip, right_knee) if not np.all(right_ankle) else 180\n",
    "\n",
    "    left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle) if np.all(left_ankle) else 0\n",
    "    right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle) if np.all(right_ankle) else 0\n",
    "\n",
    "    if ((left_hip_angle > 150 or right_hip_angle > 150) and (not np.all(left_ankle) or not np.all(right_ankle))) or \\\n",
    "       (left_knee_angle > 150 or right_knee_angle > 150):\n",
    "        return \"Standing\"\n",
    "    else:\n",
    "        return \"Sitting\"\n",
    "\n",
    "def visualize_keypoints(image, keypoints, color=(0, 255, 0)):\n",
    "    colors = {\n",
    "        'head': (0, 255, 0),\n",
    "        'body': (0, 0, 255),\n",
    "        'left_arm': (255, 0, 0),\n",
    "        'right_arm': (255, 255, 0),\n",
    "        'left_leg': (0, 255, 255),\n",
    "        'right_leg': (255, 0, 255)\n",
    "    }\n",
    "\n",
    "    skeleton = {\n",
    "        'head': [(0, 1), (0, 2), (1, 3), (2, 4)],\n",
    "        'body': [(5, 6)],\n",
    "        'left_arm': [(5, 7), (7, 9)],\n",
    "        'right_arm': [(6, 8), (8, 10)],\n",
    "        'left_leg': [(11, 13), (13, 15)],\n",
    "        'right_leg': [(12, 14), (14, 16)]\n",
    "    }\n",
    "    for part, joints in skeleton.items():\n",
    "        for joint in joints:\n",
    "            pt1, pt2 = joint\n",
    "            if keypoints[pt1][2] > 0.5 and keypoints[pt2][2] > 0.5:\n",
    "                cv2.line(image, (int(keypoints[pt1][0]), int(keypoints[pt1][1])), (int(keypoints[pt2][0]), int(keypoints[pt2][1])), colors[part], 2)\n",
    "\n",
    "    for i, (x, y, conf) in enumerate(keypoints):\n",
    "        if conf > 0.5:\n",
    "            cv2.circle(image, (int(x), int(y)), 5, colors['left_leg'] if i in [11, 13, 15] else colors['right_leg'], -1)\n",
    "    return image\n",
    "\n",
    "def match_keypoints(prev_keypoints, current_keypoints):\n",
    "    if prev_keypoints is None:\n",
    "        return list(range(len(current_keypoints)))\n",
    "    \n",
    "    prev_centroids = [np.mean(person[:2], axis=0) for person in prev_keypoints]\n",
    "    current_centroids = [np.mean(person[:2], axis=0) for person in current_keypoints]\n",
    "\n",
    "    distances = np.zeros((len(prev_centroids), len(current_centroids)))\n",
    "    for i, prev in enumerate(prev_centroids):\n",
    "        for j, curr in enumerate(current_centroids):\n",
    "            distances[i, j] = np.linalg.norm(prev - curr)\n",
    "\n",
    "    matches = []\n",
    "    for i in range(len(prev_centroids)):\n",
    "        min_index = np.argmin(distances[i])\n",
    "        matches.append(min_index)\n",
    "        distances[:, min_index] = np.inf\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def get_custom_model(model_path):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.MODEL.WEIGHTS = model_path\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "    MetadataCatalog.get(\"chair_val\").thing_classes = [\"chair\"]\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    xi1, yi1 = max(x1, x3), max(y1, y3)\n",
    "    xi2, yi2 = min(x2, x4), min(y2, y4)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x4 - x3) * (y4 - y3)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "pose_model = YOLO('pose.pt')\n",
    "model_path = \"model_final.pth\"\n",
    "chair_model = get_custom_model(model_path)\n",
    "\n",
    "video_path = \"D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Smart_Seats/Videos/One_person.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "out = cv2.VideoWriter('D:/ARTIFICIAL INTELLIGENCE/SEMESTER 1/Computer Vision and Deep Learning/CV_PROJECT_LAZY_TRAIN/human-pose-estimation-opencv/Chair_occupancy/Smart_Seats/Output/output15_combined.avi', cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width, frame_height))\n",
    "\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "prev_keypoints = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    pose_results = pose_model(frame, conf=confidence_threshold)\n",
    "    chair_outputs = chair_model(frame)\n",
    "    chair_instances = chair_outputs[\"instances\"].to(\"cpu\")\n",
    "    chair_boxes = chair_instances.pred_boxes.tensor.numpy()\n",
    "    chair_scores = chair_instances.scores.numpy()\n",
    "    chair_classes = chair_instances.pred_classes.numpy()\n",
    "\n",
    "    num_persons = len(pose_results[0].keypoints)\n",
    "    print(f\"Processing frame: {num_persons} persons detected\")\n",
    "\n",
    "    current_keypoints = [get_keypoints(pose_results[0])[i] for i in range(num_persons)]\n",
    "    \n",
    "    matches = match_keypoints(prev_keypoints, current_keypoints)\n",
    "    \n",
    "    for i, match in enumerate(matches):\n",
    "        keypoints = current_keypoints[match]\n",
    "        \n",
    "        if keypoints.size == 0:\n",
    "            continue\n",
    "\n",
    "        frame = visualize_keypoints(frame, keypoints)\n",
    "        \n",
    "        pose = classify_pose(keypoints)\n",
    "        \n",
    "        conf = pose_results[0].keypoints.conf[match].mean().item() if hasattr(pose_results[0].keypoints, 'conf') and len(pose_results[0].keypoints.conf) > match else None\n",
    "        \n",
    "        if conf is not None:\n",
    "            print(f\"Person {i+1}: Pose: {pose}, Confidence: {conf:.2f}\")\n",
    "            cv2.putText(frame, f\"Person {i+1}: Pose: {pose}, Confidence: {conf:.2f}\", \n",
    "                        (int(keypoints[0][0]), int(keypoints[0][1])-30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            print(f\"Person {i+1}: Pose: {pose}\")\n",
    "            cv2.putText(frame, f\"Person {i+1}: Pose: {pose}\", \n",
    "                        (int(keypoints[0][0]), int(keypoints[0][1])-30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    occupied_chairs = []\n",
    "    for box, score, class_id in zip(chair_boxes, chair_scores, chair_classes):\n",
    "        if score > 0.7:\n",
    "            cords = [round(x) for x in box]\n",
    "            if class_id == 0:\n",
    "                chair_center = ((cords[0] + cords[2]) // 2, (cords[1] + cords[3]) // 2)\n",
    "                occupied = False\n",
    "                best_overlap = 0\n",
    "                best_keypoints = None\n",
    "                for i in range(num_persons):\n",
    "                    keypoints = current_keypoints[i]\n",
    "                    if keypoints.size == 0:\n",
    "                        continue\n",
    "                    overlap = 0\n",
    "                    for kp in keypoints:\n",
    "                        if cords[0] <= kp[0] <= cords[2] and cords[1] <= kp[1] <= cords[3]:\n",
    "                            overlap += 1\n",
    "                    if overlap > best_overlap:\n",
    "                        best_overlap = overlap\n",
    "                        best_keypoints = keypoints\n",
    "                \n",
    "                if best_keypoints is not None and classify_pose(best_keypoints) == \"Sitting\":\n",
    "                    occupied = True\n",
    "\n",
    "                occupied_chairs.append((cords, occupied, best_keypoints))\n",
    "\n",
    "    final_chairs = []\n",
    "    for i, (box1, occupied1, keypoints1) in enumerate(occupied_chairs):\n",
    "        keep = True\n",
    "        for j, (box2, occupied2, keypoints2) in enumerate(occupied_chairs):\n",
    "            if i != j and iou(box1, box2) > 0.7:\n",
    "                keep = False\n",
    "                if not occupied1 and occupied2:\n",
    "                    keep = True\n",
    "                    occupied_chairs[j] = (box2, False, None)\n",
    "        if keep:\n",
    "            final_chairs.append((box1, occupied1))\n",
    "\n",
    "    for cords, occupied in final_chairs:\n",
    "        color = (0, 0, 255) if occupied else (0, 255, 0)\n",
    "        status = \"Occupied\" if occupied else \"Not Occupied\"\n",
    "        cv2.rectangle(frame, (cords[0], cords[1]), (cords[2], cords[3]), color, 2)\n",
    "        cv2.putText(frame, f\"Chair: {status}\",\n",
    "                    (cords[0], cords[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "    \n",
    "    prev_keypoints = current_keypoints\n",
    "\n",
    "    # Write the summary on the top right corner\n",
    "    text = f\"Chairs: {len(chair_boxes)}, Occupied: {sum(1 for _, occupied in final_chairs if occupied)}, Persons: {num_persons}\"\n",
    "    text_size, _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1, 2)\n",
    "    text_x = frame.shape[1] - text_size[0] - 10\n",
    "    text_y = text_size[1] + 10\n",
    "    cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    cv2.imshow('Pose Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
